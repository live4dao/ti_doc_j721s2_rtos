<!-- HTML header for doxygen 1.8.11-->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.14"/>
<title>TI Deep Learning Product User Guide: TIDL-RT: Meta Architectures Support</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
  $(document).ready(initResizable);
/* @license-end */</script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectlogo"><img alt="Logo" src="ti_logo.png"/></td>
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">TI Deep Learning Product User Guide
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.14 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(document).ready(function(){initNavTree('md_tidl_fsg_meta_arch_support.html','');});
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="headertitle">
<div class="title">TIDL-RT: Meta Architectures Support </div>  </div>
</div><!--header-->
<div class="contents">
<div class="toc"><h3>Table of Contents</h3>
<ul><li class="level1"><a href="#did_tidl_meta_arch_intro">Introduction</a></li>
<li class="level1"><a href="#did_tidl_meta_arch_ssd">A Single Shot Detection (SSD)</a><ul><li class="level2"><a href="#did_tidl_meta_arch_caffe_ssd">A.1 Caffe</a></li>
<li class="level2"><a href="#did_tidl_meta_arch_TF_SSD">A.2 TensorFlow/TFLite</a></li>
<li class="level2"><a href="#did_tidl_meta_arch_onnx_ssd">A.3 ONNX</a></li>
</ul>
</li>
<li class="level1"><a href="#did_tidl_yolo_v3_v5">B. YOLO Architecture</a></li>
<li class="level1"><a href="#did_tidl_retinanet">C. RetinaNet Architecture</a></li>
<li class="level1"><a href="#did_tidl_pointpillars">D. 3D Object Detection</a></li>
<li class="level1"><a href="#did_tidl_meta_arch_tidl_ssd">Example TIDL Proto File for Custom SSD network</a></li>
<li class="level1"><a href="#did_tidl_meta_arch_tidl_pointPillars">Example TIDL Proto File for Custom 3D-OD network based on pointPillars</a></li>
</ul>
</div>
<div class="textblock"><h1><a class="anchor" id="did_tidl_meta_arch_intro"></a>
Introduction</h1>
<p>TIDL-RT supports various base feature extractors / back-bone networks like Resnets, MobileNets, EfficientNets, ShuffleNets, VGG, DenseNet etc. Apart from these back-bone networks TIDL-RT also supports following post processing meta architectures from Object Detection:</p><ul>
<li>Single Shot Detection (SSD)</li>
<li>You Only Look Once (YOLO) V3 and V5 Architecture</li>
<li>RetinaNet Architecture</li>
<li>pointPillars Architecture for 3D object detection from lidar data</li>
</ul>
<h1><a class="anchor" id="did_tidl_meta_arch_ssd"></a>
A Single Shot Detection (SSD)</h1>
<h2><a class="anchor" id="did_tidl_meta_arch_caffe_ssd"></a>
A.1 Caffe</h2>
<p>TIDL-RT supports SSD networks and post processing layers as defined in Caffe-SSD implementation by original SSD authors. User should follow the following steps to provide this information to TIDL-RT via import configuration file:</p><ul>
<li>Set the metaArchType = 0 (TIDL_metaArchCaffeJacinto)</li>
<li>Set inputNetFile and inputParamsFile to point to Caffe Prototxt and Caffemodel file with post processing information</li>
</ul>
<p>User can refer following models and configuration as reference:</p><ul>
<li>JdetNet512x512:<ul>
<li>Model <a href="https://github.com/tidsp/caffe-jacinto-models/tree/caffe-0.17/trained/object_detection/voc0712/JDetNet/ssd512x512_ds_PSP_dsFac_32_fc_0_hdDS8_1_kerMbox_3_1stHdSameOpCh_1/initial">Link</a></li>
<li>Import config file : ti_dl/test/testvecs/config/import/public/caffe/tidl_import_jdetNet.txt</li>
</ul>
</li>
<li>Pelee Pascal VOC 304x304:<ul>
<li>Model <a href="https://github.com/Robert-JunWang/Pelee">Link</a></li>
<li>Import config file : ti_dl/test/testvecs/config/import/public/caffe/tidl_import_peeleNet.txt</li>
</ul>
</li>
</ul>
<h2><a class="anchor" id="did_tidl_meta_arch_TF_SSD"></a>
A.2 TensorFlow/TFLite</h2>
<p>TIDL-RT supports SSD - post processing as defined in TensorFlow Object detection API. User should follow the following steps to provide this information to TIDL-RT via import configuration file:</p><ul>
<li>Set the metaArchType = 1 (TIDL_metaArchTFSSD)</li>
<li>List of all the Box and Class prediction heads as part of outDataNamesList</li>
<li>Set metaLayersNamesList to point to the corresponding pipeline config file</li>
</ul>
<p>User can refer following model and configuration as reference:</p><ul>
<li><p class="startli">ssd_mobilenet_v2:</p><ul>
<li>Model <a href="http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v2_coco_2018_03_29.tar.gz">Link</a></li>
<li>Import Config file : ti_dl/test/testvecs/config/import/public/tensorflow/tidl_import_mobileNetv2_ssd.txt</li>
<li>Pipeline Config file : ti_dl/test/testvecs/config/import/public/mobilenet_ssd_pipeline.config</li>
</ul>
<p class="startli"><b>Note:</b> If the user is not using TensorFlow Object detection API and using SSD post processing as defined by original author, then we would recommend the method as described in <a href="#did_tidl_meta_arch_onnx_ssd">next section</a>.</p>
</li>
</ul>
<h2><a class="anchor" id="did_tidl_meta_arch_onnx_ssd"></a>
A.3 ONNX</h2>
<p>TIDL-RT supports SSD - post processing in ONNX model format. In order to enable this, TIDL-RT defines a protocol buffer format which enables providing the SSD post processing information as defined by original SSD author to TIDL. Protocol buffer definition is available in the following file: </p><pre class="fragment">├── ti_dl                             # Base Directory
│   ├── utils                        
|   |    |── tidlMetaArch/tidl_meta_arch.proto 
</pre><p>User should follow the following steps to provide this information to TIDL-RT via import configuration file:</p><ul>
<li>Set the metaArchType = 3 (TIDL_metaArchTIDLSSD)</li>
<li>List the the tensor names of the Box and Class prediction heads as in original model in the prototxt file. An example for the same is given <a href="#did_tidl_meta_arch_tidl_ssd">here</a></li>
<li>Set metaLayersNamesList to point to the prototxt file</li>
</ul>
<p>TIDL-RT model import tool would make the complete network with Flatten, Concatenate and ODPost processing layer. This mechanism is validated with models trained in Pytorch and exported to ONNX. The Object detection demo in SDK uses this flow. User can refer following model and configuration as reference:</p><ul>
<li>MLPerf ssd-resnet34:<ul>
<li>Model <a href="https://zenodo.org/record/4735664/files/ssd_resnet34_mAP_20.2.onnx">link</a></li>
<li>Import Config file: ti_dl/test/testvecs/config/import/public/onnx/tidl_import_mlperf_resnet34_ssd.txt"</li>
</ul>
</li>
</ul>
<h1><a class="anchor" id="did_tidl_yolo_v3_v5"></a>
B. YOLO Architecture</h1>
<p>TIDL-RT supports Yolo architecture (V3 and V5) for object detection post processing. This architecture also takes post processing inform as defined in <a href="#did_tidl_meta_arch_onnx_ssd">ONNX-SSD</a> section. User can refer following model and configuration as reference:</p><ul>
<li>Set the metaArchType = 4 (TIDL_metaArchTIDLYolo) for V3 architecture and metaArchType = 6 (TIDL_metaArchTIDLYoloV5) for V5 architecture</li>
<li>List the the tensor names of the Box and Class prediction heads as in original model in the prototxt file.</li>
<li>Set metaLayersNamesList to point to the prototxt file</li>
</ul>
<p>User can refer following import configuration file as reference :</p><ul>
<li>YoloV3 model:<ul>
<li>Model <a href="https://git.ti.com/cgit/jacinto-ai/jacinto-ai-modelzoo/tree/models/vision/detection/coco/edgeai-mmdet/yolov3_d53_416x416_20210116_005003_model.onnx">link</a></li>
<li>Import Config file: ti_dl/test/testvecs/config/import/public/onnx/tidl_import_yolo3.txt</li>
<li>Protocol Buffer file: ti_dl/test/testvecs/config/import/public/onnx/tidl_import_yolo3_metaarch.prototxt</li>
</ul>
</li>
</ul>
<h1><a class="anchor" id="did_tidl_retinanet"></a>
C. RetinaNet Architecture</h1>
<p>TIDL-RT supports RetinaNet architecture for object detection post processing.This architecture also takes post processing inform as defined in <a href="#did_tidl_meta_arch_onnx_ssd">ONNX-SSD</a> section. User should follow the following steps to provide this information to TIDL-RT via import configuration file:</p><ul>
<li>Set the metaArchType = 5 (TIDL_metaArchTIDLRetinaNet)</li>
<li>List the the tensor names of the Box and Class prediction heads as in original model in the prototxt file.</li>
<li>Set metaLayersNamesList to point to the prototxt file</li>
</ul>
<h1><a class="anchor" id="did_tidl_pointpillars"></a>
D. 3D Object Detection</h1>
<p>TIDL-RT supports pointPillars architecture for 3d object detection post processing.This architecture also takes post processing information as defined in <a href="#did_tidl_meta_arch_onnx_ssd">ONNX-SSD</a> section. User should follow the following steps to provide this information to TIDL-RT via import configuration file:</p><ul>
<li>Set the metaArchType = 7 (TIDL_metaArchTIDL3DOD)</li>
<li>List the the tensor names of the Box , Class and Direction prediction heads as in original model in the prototxt file. An example for the same is given <a href="#did_tidl_meta_arch_tidl_pointPillars">here</a></li>
<li>Set metaLayersNamesList to point to the prototxt file</li>
</ul>
<h1><a class="anchor" id="did_tidl_meta_arch_tidl_ssd"></a>
Example TIDL Proto File for Custom SSD network</h1>
<p>In the below example box_input: "376", 376 is the output tensor name of convolutions layer with box/loc prediction. in_width and in_height are base image resolution. This shall match with width and height parameters as set in the import config file. All the other parameters are as defined by Original Caffe-SSD implementation.</p>
<div class="fragment"><div class="line">name: &quot;TIAD SSD ARCH&quot;</div><div class="line"></div><div class="line">caffe_ssd {</div><div class="line">  name: &quot;ssd_post_proc&quot;</div><div class="line">  box_input: &quot;376&quot;</div><div class="line">  box_input: &quot;380&quot;</div><div class="line">  box_input: &quot;384&quot;</div><div class="line">  box_input: &quot;388&quot;</div><div class="line">  box_input: &quot;392&quot;</div><div class="line">  box_input: &quot;396&quot;</div><div class="line">  class_input: &quot;378&quot;</div><div class="line">  class_input: &quot;382&quot;</div><div class="line">  class_input: &quot;386&quot;</div><div class="line">  class_input: &quot;390&quot;</div><div class="line">  class_input: &quot;394&quot;</div><div class="line">  class_input: &quot;398&quot;</div><div class="line">  output: &quot;psd_bboxes&quot;</div><div class="line">  in_width: 768</div><div class="line">  in_height: 384</div><div class="line"></div><div class="line">  prior_box_param {</div><div class="line">    min_size: 46.1</div><div class="line">    max_size: 113.7</div><div class="line">    aspect_ratio: 3.0</div><div class="line">    flip: true</div><div class="line">    clip: false</div><div class="line">    variance: 0.1</div><div class="line">    variance: 0.1</div><div class="line">    variance: 0.2</div><div class="line">    variance: 0.2</div><div class="line">    offset: 0.5</div><div class="line">    step: 16</div><div class="line">  }</div><div class="line"></div><div class="line">  prior_box_param {</div><div class="line">    min_size: 113.7</div><div class="line">    max_size: 181.2</div><div class="line">    aspect_ratio: 3.0</div><div class="line">    aspect_ratio: 5.0</div><div class="line">    flip: true</div><div class="line">    clip: false</div><div class="line">    variance: 0.1</div><div class="line">    variance: 0.1</div><div class="line">    variance: 0.2</div><div class="line">    variance: 0.2</div><div class="line">    offset: 0.5</div><div class="line">    step: 32</div><div class="line">  }</div><div class="line"></div><div class="line">  prior_box_param {</div><div class="line">    min_size: 181.2</div><div class="line">    max_size: 248.8</div><div class="line">    aspect_ratio: 3.0</div><div class="line">    aspect_ratio: 5.0</div><div class="line">    flip: true</div><div class="line">    clip: false</div><div class="line">    variance: 0.1</div><div class="line">    variance: 0.1</div><div class="line">    variance: 0.2</div><div class="line">    variance: 0.2</div><div class="line">    offset: 0.5</div><div class="line">    step: 64</div><div class="line">  }</div><div class="line"></div><div class="line">  prior_box_param {</div><div class="line">    min_size: 248.8</div><div class="line">    max_size: 316.4</div><div class="line">    aspect_ratio: 3.0</div><div class="line">    aspect_ratio: 5.0</div><div class="line">    flip: true</div><div class="line">    clip: false</div><div class="line">    variance: 0.1</div><div class="line">    variance: 0.1</div><div class="line">    variance: 0.2</div><div class="line">    variance: 0.2</div><div class="line">    offset: 0.5</div><div class="line">    step: 128</div><div class="line">  }</div><div class="line"></div><div class="line"></div><div class="line">  prior_box_param {</div><div class="line">    min_size: 316.4</div><div class="line">    max_size: 384.0</div><div class="line">    aspect_ratio: 3.0</div><div class="line">    aspect_ratio: 5.0</div><div class="line">    flip: true</div><div class="line">    clip: false</div><div class="line">    variance: 0.1</div><div class="line">    variance: 0.1</div><div class="line">    variance: 0.2</div><div class="line">    variance: 0.2</div><div class="line">    offset: 0.5</div><div class="line">    step_w: 256</div><div class="line">    step_h: 192</div><div class="line">  }</div><div class="line"></div><div class="line">  prior_box_param {</div><div class="line">    min_size: 384.0</div><div class="line">    max_size: 768.0</div><div class="line">    aspect_ratio: 3.0</div><div class="line">    aspect_ratio: 5.0</div><div class="line">    flip: true</div><div class="line">    clip: false</div><div class="line">    variance: 0.1</div><div class="line">    variance: 0.1</div><div class="line">    variance: 0.2</div><div class="line">    variance: 0.2</div><div class="line">    offset: 0.5</div><div class="line">    step: 384</div><div class="line">  }</div><div class="line">  detection_output_param {</div><div class="line">    num_classes: 4</div><div class="line">    share_location: true</div><div class="line">    background_label_id: 0</div><div class="line">    nms_param {</div><div class="line">      nms_threshold: 0.60</div><div class="line">      top_k: 100</div><div class="line">    }</div><div class="line">    code_type: CENTER_SIZE</div><div class="line">    keep_top_k: 100</div><div class="line">    confidence_threshold: 0.5</div><div class="line">  }</div><div class="line"></div><div class="line">}</div></div><!-- fragment --> <h1><a class="anchor" id="did_tidl_meta_arch_tidl_pointPillars"></a>
Example TIDL Proto File for Custom 3D-OD network based on pointPillars</h1>
<p>A sample prototext file pointPillars network is provided below. In the below example 208, 206, 207 are the box,class, location head convolution output for pointPillars network. voxel_size_x and voxel_size_y are voxel sizes in meters. Valid area range is provided through min_x/y/z and max_x/y/z, and those values are in meters. Valid area is divided in multiple voxels each of size voxel_size_x/voxel_size_y as described in pointPillars original paper. max_points_per_voxel is the maximum number of points allowed inside in each voxel. If any voxel has 3d points more than max_points_per_voxel, then extra 3D points are discarded.</p>
<div class="fragment"><div class="line">name: &quot;3dod_ssd&quot;</div><div class="line">tidl_3dod {</div><div class="line">  name: &quot;point_pillars&quot;</div><div class="line"></div><div class="line">  min_x: 0.0</div><div class="line">  max_x: 69.120</div><div class="line">  min_y: -39.680</div><div class="line">  max_y: 39.680</div><div class="line">  min_z: -1.78</div><div class="line">  max_z: -1.78</div><div class="line"></div><div class="line">  voxel_size_x : 0.16</div><div class="line">  voxel_size_y : 0.16</div><div class="line">  max_points_per_voxel : 32</div><div class="line"></div><div class="line">  box_input:   &quot;208&quot;</div><div class="line">  class_input: &quot;206&quot;</div><div class="line">  dir_input:   &quot;207&quot;</div><div class="line"></div><div class="line">  prior_box_3dod_param {</div><div class="line">    anchor_width: 1.6</div><div class="line">    anchor_length: 3.9</div><div class="line">    anchor_height: 1.56</div><div class="line">    rotation: 0.0</div><div class="line">    rotation: 90.0</div><div class="line">  }</div><div class="line"></div><div class="line">  detection_output_param {</div><div class="line">    num_classes: 1</div><div class="line">    share_location: true</div><div class="line">    background_label_id: -1</div><div class="line">    nms_param {</div><div class="line">      nms_threshold: 0.01</div><div class="line">      top_k: 100</div><div class="line">    }</div><div class="line">    code_type: CODE_TYPE_3DOD</div><div class="line">    keep_top_k: 100</div><div class="line">    confidence_threshold: 0.1</div><div class="line">  }</div><div class="line">}</div></div><!-- fragment --> </div></div><!-- contents -->
</div><!-- doc-content -->
<!-- HTML footer for doxygen 1.8.11-->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer">Generated by
    <a href="http://www.doxygen.org/index.html">
    <img class="footer" src="doxygen.png" alt="doxygen"/></a> 1.8.14 </li>
  </ul>
</div>
</body>
</html>
