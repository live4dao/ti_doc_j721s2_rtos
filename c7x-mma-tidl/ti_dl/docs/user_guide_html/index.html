<!-- HTML header for doxygen 1.8.11-->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.14"/>
<title>TI Deep Learning Product User Guide: TIDL - TI Deep Learning Product</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
  $(document).ready(initResizable);
/* @license-end */</script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectlogo"><img alt="Logo" src="ti_logo.png"/></td>
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">TI Deep Learning Product User Guide
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.14 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(document).ready(function(){initNavTree('index.html','');});
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="headertitle">
<div class="title">TIDL - TI Deep Learning Product </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p>TIDL is a comprehensive software product for acceleration of Deep Neural Networks (DNNs) on TI's embedded devices. It supports heterogeneous execution of DNNs across cortex-A based MPUs, TI’s latest generation C7x DSP and TI's DNN accelerator (MMA). TIDL is released as part of TI's Software Development Kit (SDK) along with additional computer vision functions and optimized libraries including OpenCV. TIDL is available on a variety of embedded devices from Texas Instruments.</p>
<p>TIDL is a fundamental software component of <a href="https://www.ti.com/edgeai"><b>TI’s Edge AI solution</b></a>. TI's Edge AI solution simplifies the whole product life cycle of DNN development and deployment by providing a rich set of tools and optimized libraries. DNN based product development requires two main streams of expertise:</p><ul>
<li><b>Data Scientists</b>, who can design and train DNNs for targeted applications</li>
<li><b>Embedded System Engineers</b>, who can design and develop inference solutions for real time execution of DNNs on low power embedded device</li>
</ul>
<p>TI's Edge AI solution provides the right set of tools for both of these categories:</p>
<ul>
<li><a href="https://dev.ti.com/edgeai/"><b>Edge AI Studio</b></a>: Integrated development environment for development of AI applications for edge processors, hosting tools like <b>Model Composer</b> to train,compile and deploy models with click of mouse button and <b>Model Analyzer</b> to let you evaluate and analyze deep learning model performance on TI devices from your browser in minutes</li>
<li><a href="https://github.com/TexasInstruments/edgeai-modelzoo"><b>Model zoo</b></a>: A large collection of pre-trained models for data scientists, which along with TI's Model Selection Tool enables picking the ideal model for TI's embedded devices</li>
<li><a href="https://github.com/TexasInstruments/edgeai"><b>Training and quantization tools</b></a> for popular frameworks, allowing data scientists to make DNNs more suitable for TI devices</li>
<li><a href="https://github.com/TexasInstruments/edgeai-benchmark"><b>Edge AI Benchmark</b></a>: A python based framework which can allow you to perform accuracy and performance benchmark. Accuracy benchmark can be performed without development board, but for performance benchmark, a development board is needed.</li>
<li><a href="index.html"><b>TIDL</b></a>: Optimized inference solutions primarily targeted for compilation and deployment of pre-trained models. Model compilation happens on X86 machine and associated tools and examples are provided in <a href="https://github.com/TexasInstruments/edgeai-tidl-tools">Edge AI TIDL Tools</a>. Model inference can happen on X86 machine (host emulation mode) or on development board with TI SOC. <a href="https://github.com/TexasInstruments/edgeai-tidl-tools">Edge AI TIDL Tools</a> also provides examples to be directly used on X86 target and same can be used on development board with TI SOC. For deployment and execution on the development board, one has to use this package.</li>
</ul>
<p>The figure below illustrates the work flow of DNN development and deployment on TI devices: <br />
</p><div class="image">
<img src="dnn-workflow.png" alt="dnn-workflow.png"/>
</div>
<p>TIDL provides multiple deployment options with industry defined inference engines as listed below. These inference engines are being referred as Open Source Run Times (<a href="usergroup0.html"><b>OSRT</b></a>) in this document.</p><ul>
<li><b>TFLite Runtime</b>: <a href="https://www.tensorflow.org/lite/guide/inference">TensorFlow Lite</a> based inference with heterogeneous execution on cortex-A** + C7x-MMA,refer Tensorflow Lite runtime in <a href="https://github.com/TexasInstruments/edgeai-tidl-tools">Edge AI TIDL Tools</a> for more details</li>
<li><b>ONNX RunTime</b>: <a href="https://www.onnxruntime.ai/">ONNX Runtime</a> based inference with heterogeneous execution on cortex-A** + C7x-MMA, refer ONNX Runtime in <a href="https://github.com/TexasInstruments/edgeai-tidl-tools">Edge AI TIDL Tools</a> for more details.</li>
<li><b>TVM/Neo-AI RunTime</b>: <a href="https://tvm.apache.org">TVM</a>/<a href="https://github.com/neo-ai/neo-ai-dlr">Neo-AI-DLR</a> based inference with heterogeneous execution on cortex-A** + C7x-MMA, refer TVM/Neo-AI-DLR in <a href="https://github.com/TexasInstruments/edgeai-tidl-tools">Edge AI TIDL Tools</a> for more details.</li>
</ul>
<p>TIDL also provides an openVX based inference solution, being referred as <a href="usergroup1.html">TIDL-RT</a> in this document. It supports execution of DNNs only on C7x-MMA and DNNs have to be constructed using the operators supported by TIDL-RT. OSRT makes use of TIDL-RT as part of its backend to offload sub graph(s) to C7x-MMA. Please refer, <a href="https://github.com/TexasInstruments/edgeai-tidl-tools">Edge AI TIDL Tools</a> for more details</p>
<p><b>We recommend users to use OSRT for a better user experience and a richer coverage of neural networks. A comparison table with more criterias is provided below</b></p>
<table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadNone">Criteria  </th><th class="markdownTableHeadNone">TIDL-RT  </th><th class="markdownTableHeadNone">OSRT   </th></tr>
<tr class="markdownTableBody" class="markdownTableRowOdd">
<td class="markdownTableBodyNone">Operator Coverage  </td><td class="markdownTableBodyNone">~40 accelerated operators  </td><td class="markdownTableBodyNone">All the operators supported by TFLite and ONNX   </td></tr>
<tr class="markdownTableBody" class="markdownTableRowEven">
<td class="markdownTableBodyNone">Inference Speed  </td><td class="markdownTableBodyNone">Best  </td><td class="markdownTableBodyNone">Similar to TIDL-RT if entire DNN is offloaded to C7x-MMA   </td></tr>
<tr class="markdownTableBody" class="markdownTableRowOdd">
<td class="markdownTableBodyNone">Application Interface  </td><td class="markdownTableBodyNone">C/C++  </td><td class="markdownTableBodyNone">C/C++ and Python   </td></tr>
<tr class="markdownTableBody" class="markdownTableRowEven">
<td class="markdownTableBodyNone">Ease of Use  </td><td class="markdownTableBodyNone">Good  </td><td class="markdownTableBodyNone">Better than TIDL-RT due to (A) Higher operator coverage (B) Industry standard APIs (C) Python support   </td></tr>
<tr class="markdownTableBody" class="markdownTableRowOdd">
<td class="markdownTableBodyNone">Portability  </td><td class="markdownTableBodyNone">Portable to any TI SOC with TIDL product support  </td><td class="markdownTableBodyNone">TI SOC, non TI SOC with OSRT support enabled   </td></tr>
<tr class="markdownTableBody" class="markdownTableRowEven">
<td class="markdownTableBodyNone">Operating system  </td><td class="markdownTableBodyNone">Linux (OOB offering), Minimal dependency on other HLOS so easy to migrate  </td><td class="markdownTableBodyNone">Linux (OOB offering), Requires porting of open source run time engines (e.g. TFLiteRT, ONNXRT etc) to 3P OS from OS vendor   </td></tr>
<tr class="markdownTableBody" class="markdownTableRowOdd">
<td class="markdownTableBodyNone">Safety  </td><td class="markdownTableBodyNone">Suitable  </td><td class="markdownTableBodyNone">Depends on (A) Proven in use for OSRT components and (B) Availability of these components by 3P OS vendors for safe OS   </td></tr>
</table>
<p>** <em>TDA4AL/TDA4VE/TDA4VL has cortex-A72 as its MPU, refer to the device TRM to know which cortex-A MPU</em> it contains. </p>
</div></div><!-- contents -->
</div><!-- doc-content -->
<!-- HTML footer for doxygen 1.8.11-->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer">Generated by
    <a href="http://www.doxygen.org/index.html">
    <img class="footer" src="doxygen.png" alt="doxygen"/></a> 1.8.14 </li>
  </ul>
</div>
</body>
</html>
