<!-- HTML header for doxygen 1.8.11-->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.14"/>
<title>TI Deep Learning Product User Guide: Getting Started with TIDL-RT</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
  $(document).ready(initResizable);
/* @license-end */</script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectlogo"><img alt="Logo" src="ti_logo.png"/></td>
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">TI Deep Learning Product User Guide
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.14 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(document).ready(function(){initNavTree('md_tidl_user_model_deployment.html','');});
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="headertitle">
<div class="title">Getting Started with TIDL-RT </div>  </div>
</div><!--header-->
<div class="contents">
<div class="toc"><h3>Table of Contents</h3>
<ul><li class="level1"><a href="#tidl_gs_intro">Introduction</a></li>
<li class="level1"><a href="#tidl_gs_setup">Setting up the environment</a></li>
<li class="level1"><a href="#tidl_gs_import_models">Importing models</a><ul><li class="level2"><a href="#tidl_gs_import_mbv2">Importing MobileNetV2 model for image classification</a></li>
<li class="level2"><a href="#tidl_gs_import_peleenet">Importing PeleeNet model for object detection</a></li>
<li class="level2"><a href="#tidl_gs_import_jsegnet">Importing JSegNet21V2 model for semantic segmentation</a></li>
</ul>
</li>
<li class="level1"><a href="#tidl_gs_executePC">Executing imported models on a X86 PC</a><ul><li class="level2"><a href="#tidl_gs_exec_mbv2">Executing MobileNetV2 model for image classification</a></li>
<li class="level2"><a href="#tidl_gs_exec_pn">Executing PeleeNet model for object detection</a></li>
<li class="level2"><a href="#tidl_gs_exec_jsegnet">Executing JSegNet21V2 model for semantic segmentation</a></li>
</ul>
</li>
<li class="level1"><a href="#tidl_gs_executeEVM">Executing imported models on Development Board</a></li>
<li class="level1"><a href="#tidl_gs_summary">Summary</a></li>
</ul>
</div>
<div class="textblock"><h1><a class="anchor" id="tidl_gs_intro"></a>
Introduction</h1>
<blockquote class="doxtable">
<p><b>Important Note</b>: Readers are advised to read <a class="el" href="readme_8md.html">TIDL Product summary</a> and <a class="el" href="md_tidl_overview.html">TIDL-RT overview</a> before reading this page. </p>
</blockquote>
<p>This page is targeted towards readers who have TIDL already downloaded and want to work with TIDL-RT which is the low level user interface of TIDL. Please note that TIDL provides a higher level software interface via open source runtimes as described in <a href="usergroup0.html">Open Source Runtime</a>. <b>Users are highly recommended to work with the open source run time interface.</b></p>
<blockquote class="doxtable">
<p><b>Note</b><br />
Before proceeding, please make sure that</p><ul>
<li>You can see the software package in your system as described in <a class="el" href="md_tidl_package_contents.html">TIDL package contents</a>.</li>
<li>You have downloaded all the dependencies as <a class="el" href="md_tidl_dependency_info.html">described</a>.</li>
<li>If you are not familiar with concepts of deep learning or machine learning, and if this is your first experience with convolution neural networks (CNNs), it is recommended that you get started <a class="el" href="md_tidl_dl_cnn_useful_links.html">here</a>. </li>
</ul>
</blockquote>
<p>Using <b>TIDL-RT</b>, you are expected to be able to:</p>
<ul>
<li>Import trained network models into <code>.bin</code> files that can be used by <b>TIDL-RT Inference</b>.<ul>
<li><code>tidlModelImport</code> converts networks trained via open source frameworks (like Caffe or TensorFlow) into a format that <b>TIDL-RT Inference</b> can use to execute these networks for inference.</li>
<li><code>tidlModelImport</code> uses the <code>quantization statistics</code> tool internally to measure any deviation in inference accuracies and layer level outputs arising due to quantization.</li>
<li><code>tidlModelImport</code> uses the <code>graph compiler</code> tool internally to generate optimized execution order and dataflow sequences to maximize inference performance.</li>
</ul>
</li>
<li>Execute the network on PC using the imported <code>.bin</code> files and validate the results.</li>
<li>Execute the network on development board using the imported <code>.bin</code> files and validate the results.</li>
</ul>
<blockquote class="doxtable">
<p><b>Note</b><br />
 The following model formats are currently supported:</p>
<ul>
<li>Caffe models (using <code>.caffemodel</code> and <code>.prototxt</code> files)</li>
<li>Tensorflow models (using <code>.pb</code> or <code>.tflite</code> files)</li>
<li>ONNX models (<code>.onnx</code> files) </li>
</ul>
</blockquote>
<p>This guide demonstrates the above features and documents the steps that shall help you get started on <b>TIDL-RT</b> inference.</p>
<h1><a class="anchor" id="tidl_gs_setup"></a>
Setting up the environment</h1>
<p>Follow the steps defined in <a class="el" href="md_tidl_dependency_info.html">Dependent Software Components section</a></p>
<h1><a class="anchor" id="tidl_gs_import_models"></a>
Importing models</h1>
<p>This section elaborates further on the import process with examples on importing models trained with Caffe and TensorFlow into <b>TIDL-RT</b>. The following models will be used in this guide:</p>
<ul>
<li><em>MobileNetV2</em> TensorFlow model for <em>image classification</em></li>
<li><em>PeleeNet</em> Caffe model for <em>object detection</em></li>
<li><em>JSegNet21V2</em> Caffe model for <em>semantic segmentation</em></li>
</ul>
<blockquote class="doxtable">
<p><b>Note</b><br />
The installation does not create the directories required for storing the downloaded models mentioned in this guide. You need to create the directories as required, if they are not already present. </p>
</blockquote>
<blockquote class="doxtable">
<p><b>Note</b><br />
The paths used in this guide are for the purpose of demonstration. You can create your own configuration file (containing the appropriate paths for collecting input models and storing output files), and pass that file's location as an argument to the <code>tidlModelImport</code> tool. </p>
</blockquote>
<h2><a class="anchor" id="tidl_gs_import_mbv2"></a>
Importing MobileNetV2 model for image classification</h2>
<p><b>Downloading the model</b></p>
<p>Download the tarball containing the trained model from <a href="https://storage.googleapis.com/mobilenet_v2/checkpoints/mobilenet_v2_1.0_224.tgz">here</a>.</p>
<p>You need to extract <code>mobilenet_v2_1.0_224_frozen.pb</code> from the tarball and place it in the <code>ti_dl/test/testvecs/models/public/tensorflow/mobilenet_v2</code> directory.</p>
<p>The downloaded TensorFlow models cannot be imported until they are optimized for inference. Execute <code>optimize_for_inference.py</code> (distributed with TensorFlow installation) to create an optimized model file.</p>
<div class="fragment"><div class="line">user@ubuntu-pc$ python optimize_for_inference.py \</div><div class="line">                       --input=${TIDL_INSTALL_PATH}/ti_dl/test/testvecs/models/public/tensorflow/mobilenet_v2/mobilenet_v2_1.0_224_frozen.pb \</div><div class="line">                       --output=${TIDL_INSTALL_PATH}/ti_dl/test/testvecs/models/public/tensorflow/mobilenet_v2/mobilenet_v2_1.0_224_final.pb \</div><div class="line">                       --input_names=&quot;input&quot; \</div><div class="line">                       --output_names=&quot;MobilenetV2/Predictions/Softmax&quot;</div></div><!-- fragment --><p><b>Importing the model</b></p>
<p>To import models using the <code>tidlModelImport</code> tool, you need to use a configuration file that provides the import parameters to the tool. The various parameters and the supported values for each parameters are documented <a class="el" href="md_tidl_model_import.html">here</a>.</p>
<p>You can use the configuration file <code>ti_dl/test/testvecs/config/import/public/tensorflow/tidl_import_mobileNetv2.txt</code> (distributed with the installation) to import this model.</p>
<p>Execute the import tool to import the model.</p>
<blockquote class="doxtable">
<p><b>For Linux Users</b> </p><pre class="fragment">user@ubuntu-pc$ cd ${TIDL_INSTALL_PATH}/ti_dl/utils/tidlModelImport
user@ubuntu-pc$ ./out/tidl_model_import.out ${TIDL_INSTALL_PATH}/ti_dl/test/testvecs/config/import/public/tensorflow/tidl_import_mobileNetv2.txt --numParamBits 15
</pre> </blockquote>
<blockquote class="doxtable">
<p><b>For Windows Users</b> </p><pre class="fragment">C:\&gt; cd %TIDL_INSTALL_PATH%\ti_dl\utils\tidlModelImport
C:\&gt; out/tidl_model_import.out.exe %TIDL_INSTALL_PATH%\ti_dl\test\testvecs\config\import\public\tensorflow\tidl_import_mobileNetv2.txt  --numParamBits 15
</pre> </blockquote>
<blockquote class="doxtable">
<p><b>Note</b><br />
MobileNetV2 trained on TensorFlow needs 16 bits for better accuracy. Therefore, it is required to override the default value of <code>numParamBits</code> while importing. </p>
</blockquote>
<p>The import tool will perform quantization and carry out graph compilation and generate the following files:</p>
<ul>
<li>Compiled network and I/O <code>.bin</code> files used for inference<ul>
<li>Compiled network file in <code>ti_dl/test/testvecs/config/tidl_models/tensorflow/tidl_net_mobilenet_v2_1.0_224.bin</code> containing the layers in the order of execution, and the layers parameters (weights , bias etc).</li>
<li>Compiled I/O file in <code>ti_dl/test/testvecs/config/tidl_models/tensorflow/tidl_net_mobilenet_v2_1.0_2241.bin</code> containing the dataflow sequences.</li>
</ul>
</li>
</ul>
<p>If you built the <code>tidlModelGraphviz</code> tool as described in <a class="el" href="md_tidl_dependency_info.html">Dependent Software Components section</a>, the network graph representation is also generated in <code>ti_dl/test/testvecs/config/tidl_models/tensorflow/tidl_net_mobilenet_v2_1.0_224.bin.svg</code>.</p>
<h2><a class="anchor" id="tidl_gs_import_peleenet"></a>
Importing PeleeNet model for object detection</h2>
<p><b>Downloading model</b></p>
<p>Download the tarball containing the trained model from <a href="https://drive.google.com/file/d/1KJHKYQ2nChZXlxroZRpg-tRsksTXUhe9/view">here</a>.</p>
<p>You need to extract <code>pelee_304x304_acc7094.caffemodel</code> and <code>deploy.prototxt</code> from the tarball and put it inside <code>ti_dl/test/testvecs/models/public/caffe/peele/pelee_voc/</code> directory.</p>
<p>The downloaded pelee model should be imported with a higher <code>confidence_threshold</code> parameter for better accuracy. Modify the file <code>ti_dl/test/testvecs/models/public/caffe/peele/pelee_voc/deploy.prototxt</code> to use <code>0.4</code> as <code>confidence_threshold</code>.</p>
<div class="fragment"><div class="line">...</div><div class="line">    keep_top_k: 200</div><div class="line">    confidence_threshold: 0.4</div><div class="line">  }</div><div class="line">...</div></div><!-- fragment --><p><b>Importing the model</b></p>
<p>After the above changes are made to the model, it can be imported by following the steps similar to the ones described in <a href="#tidl_gs_import_mbv2">Importing MobileNetV2 model for image classification</a>. You can use <code>ti_dl/test/testvecs/config/import/public/caffe/tidl_import_peeleNet.txt</code> (distributed with the installation) to import the model.</p>
<blockquote class="doxtable">
<p><b>For Linux Users</b> </p><pre class="fragment">user@ubuntu-pc$ cd ${TIDL_INSTALL_PATH}/ti_dl/utils/tidlModelImport
user@ubuntu-pc$ ./out/tidl_model_import.out ${TIDL_INSTALL_PATH}/ti_dl/test/testvecs/config/import/public/caffe/tidl_import_peeleNet.txt
</pre> </blockquote>
<blockquote class="doxtable">
<p><b>For Windows Users</b> </p><pre class="fragment">C:\&gt; cd %TIDL_INSTALL_PATH%\ti_dl\utils\tidlModelImport
C:\&gt; out/tidl_model_import.out.exe %TIDL_INSTALL_PATH%\ti_dl\test\testvecs\config\import\public\caffe\tidl_import_peeleNet.txt
</pre> </blockquote>
<p>The following files are generated by the import:</p>
<ul>
<li>Compiled network and I/O <code>.bin</code> files used for inference<ul>
<li>Compiled network file in <code>ti_dl/test/testvecs/config/tidl_models/caffe/tidl_net_peele_300.bin</code></li>
<li>Compiled I/O file in <code>ti_dl/test/testvecs/config/tidl_models/caffe/tidl_io_peele_300_1.bin</code></li>
</ul>
</li>
</ul>
<p>If you built the <code>tidlModelGraphviz</code> tool as described in <a class="el" href="md_tidl_dependency_info.html">Dependent Software Components section</a>, the network graph representation is also generated in <code>ti_dl/test/testvecs/config/tidl_models/caffe/tidl_net_peele_300.bin.svg</code>.</p>
<h2><a class="anchor" id="tidl_gs_import_jsegnet"></a>
Importing JSegNet21V2 model for semantic segmentation</h2>
<p><b>Downloading the model</b></p>
<p>Download the trained model from <a href="https://github.com/tidsp/caffe-jacinto-models/blob/caffe-0.17/trained/image_segmentation/cityscapes5_jsegnet21v2/sparse/cityscapes5_jsegnet21v2_iter_60000.caffemodel">here</a> and put it in <code>ti_dl/test/testvecs/models/public/caffe/jsegNet21</code> directory.</p>
<blockquote class="doxtable">
<p><b>Note</b><br />
Do not use <code>save link as</code> or <code>copy link location</code> options to download binary files from github.com, use the <code>Download</code> button instead. </p>
</blockquote>
<p>Download the <code>deploy.prototxt</code> file from <a href="https://github.com/tidsp/caffe-jacinto-models/blob/caffe-0.17/trained/image_segmentation/cityscapes5_jsegnet21v2/sparse/deploy.prototxt">here</a> and put it in <code>ti_dl/test/testvecs/models/public/caffe/jsegNet21</code> directory.</p>
<blockquote class="doxtable">
<p><b>Note</b><br />
Do not use <code>save link as</code> or <code>copy link location</code> options to download text files from github.com, use the <code>Raw</code> button to open the file and then use <code>save as ...</code> option. </p>
</blockquote>
<p><b>Importing the model</b></p>
<p>The model can be imported by following steps similar to the the ones described in <a href="#tidl_gs_import_mbv2">Importing MobileNetV2 model for image classification</a>. You can use <code>ti_dl/test/testvecs/config/import/public/caffe/tidl_import_jSegNet.txt</code> (distributed with the installation) to import the model.</p>
<blockquote class="doxtable">
<p><b>For Linux Users</b> </p><pre class="fragment">user@ubuntu-pc$ cd ${TIDL_INSTALL_PATH}/ti_dl/utils/tidlModelImport
user@ubuntu-pc$ ./out/tidl_model_import.out ${TIDL_INSTALL_PATH}/ti_dl/test/testvecs/config/import/public/caffe/tidl_import_jSegNet.txt
</pre> </blockquote>
<blockquote class="doxtable">
<p><b>For Windows Users</b> </p><pre class="fragment">C:\&gt; cd %TIDL_INSTALL_PATH%/ti_dl/utils/tidlModelImport
C:\&gt; out/tidl_model_import.out.exe %TIDL_INSTALL_PATH%\ti_dl\test\testvecs\config\import\public\caffe\tidl_import_jSegNet.txt
</pre> </blockquote>
<p>The following files are generated by the import:</p>
<ul>
<li>Compiled network and I/O <code>.bin</code> files used for inference<ul>
<li>Compiled network file in <code>ti_dl/test/testvecs/config/tidl_models/caffe/tidl_net_jSegNet_1024x512.bin</code></li>
<li>Compiled I/O file in <code>ti_dl/test/testvecs/config/tidl_models/caffe/tidl_io_jSegNet_1024x512_1.bin</code></li>
</ul>
</li>
</ul>
<p>If you built the <code>tidlModelGraphviz</code> tool as described in <a class="el" href="md_tidl_dependency_info.html">Dependent Software Components section</a>, the network graph representation is also generated at <code>ti_dl/test/testvecs/config/tidl_models/caffe/tidl_net_jSegNet_1024x512.bin.svg</code>.</p>
<h1><a class="anchor" id="tidl_gs_executePC"></a>
Executing imported models on a X86 PC</h1>
<p>The installation comes with a PC simulation tool <code>ti_dl/test/PC_dsp_test_dl_algo.out</code> that can be used to execute imported <code>.bin</code> files and verify the inference result before running them on a development board. This helps in easily identifying issues with the model and debugging.</p>
<p>The PC simulation tool uses the file <code>ti_dl/test/testvecs/config/config_list.txt</code> to read the list of inference tests to run. The format of the file is as follows:</p>
<div class="fragment"><div class="line">1 /path/to/inference/parameter/file/to/be/executed/1</div><div class="line">1 /path/to/inference/parameter/file/to/be/executed/2</div><div class="line">1 /path/to/inference/parameter/file/to/be/executed/3</div><div class="line">2 /comment/line/./continue/to/the/next/line</div><div class="line">2 /comment/line/./continue/to/the/next/line</div><div class="line">1 /path/to/inference/parameter/file/to/be/executed/4</div><div class="line">1 /path/to/inference/parameter/file/to/be/executed/5</div><div class="line">0 /stop/processing/after/this/line</div><div class="line">...</div></div><!-- fragment --><p>Each line that starts with <code>1</code> must point to a file containing the inference parameters to run an imported model. The various parameters and the supported values for each parameters are documented <a class="el" href="md_tidl_sample_test.html">here</a>.</p>
<blockquote class="doxtable">
<p><b>Note</b><br />
The lines that start with <code>2</code> are ignored.<br />
The test sequence stops when it hits a line that starts with <code>0</code>. </p>
</blockquote>
<blockquote class="doxtable">
<p><b>Note</b><br />
The paths in the file <code>ti_dl/test/testvecs/config/config_list.txt</code> (e.g. <code>/path/to/inference/parameter/file/to/be/executed/1</code>) must be relative to <code>ti_dl/utils/test</code>.<br />
For example, to add the inference parameter file <code>ti_dl/test/testvecs/config/infer/public/caffe/tidl_infer_pelee.txt</code> to the list, you must add the following: </p><pre class="fragment">1 testvecs/config/infer/public/caffe/tidl_infer_pelee.txt
</pre> </blockquote>
<p>In this section, we will test the models imported in <a href="#tidl_gs_import_models">Importing models</a> using the inference parameter files distributed with the installation.</p>
<h2><a class="anchor" id="tidl_gs_exec_mbv2"></a>
Executing MobileNetV2 model for image classification</h2>
<p>Add the following lines at the beginning of <code>ti_dl/test/testvecs/config/config_list.txt</code>: </p><div class="fragment"><div class="line">1 testvecs/config/infer/public/tensorflow/tidl_infer_mobileNetv2.txt</div><div class="line">0</div></div><!-- fragment --><p>Execute command <code>PC_dsp_test_dl_algo.out</code> from <code>ti_dl/test</code> directory.</p>
<div class="fragment"><div class="line">user@ubuntu-pc$ cd ${TIDL_INSTALL_PATH}/ti_dl/test</div><div class="line">user@ubuntu-pc$ ./PC_dsp_test_dl_algo.out</div><div class="line"></div><div class="line">Processing config file #0 : testvecs/config/infer/public/tensorflow/tidl_infer_mobileNetv2.txt</div><div class="line"> ----------------------- TIDL Process with REF_ONLY FLOW ------------------------</div><div class="line"></div><div class="line">#    0 . .. T     655.09  ... A :   896, 1.0000, 1.0000,   896 .... ..... </div><div class="line">user@ubuntu-pc$ </div></div><!-- fragment --><p><b>Decoding the output</b></p>
<p>The test uses the <code>ti_dl/test/testvecs/input/airshow.bmp</code> as input image and <code>896</code> as test label.</p>
<div class="image">
<img src="airshow.bmp" alt="airshow.bmp"/>
<div class="caption">
Input image for classification</div></div>
 <blockquote class="doxtable">
<p><b>Note</b><br />
This information is obtained from the input configuration file <code>ti_dl/test/testvecs/config/classification_list_1.txt</code>.<br />
The input configuration file is provided as <code>inData</code> parameter in <code>ti_dl/test/testvecs/config/infer/public/tensorflow/tidl_infer_mobileNetv2.txt</code> </p>
</blockquote>
<p>The numbers printed by the classification test represent the following information:</p>
<ul>
<li>Time taken by PC simulation</li>
<li>Classification Results<ul>
<li>Test image label</li>
<li>TOP-1 accuracy</li>
<li>TOP-5 accuracy</li>
<li>Inferred label</li>
</ul>
</li>
</ul>
<p>For example, the above output indicates that the simulation took <code>655.09</code> milliseconds, the test input label was <code>896</code>, the inferred label was <code>896</code>, and the TOP-1 and TOP-5 accuracies are both <code>1.0</code>.</p>
<h2><a class="anchor" id="tidl_gs_exec_pn"></a>
Executing PeleeNet model for object detection</h2>
<p>Add the following lines at the beginning of <code>ti_dl/test/testvecs/config/config_list.txt</code>:</p>
<div class="fragment"><div class="line">1 testvecs/config/infer/public/caffe/tidl_infer_pelee.txt</div><div class="line">0</div></div><!-- fragment --><p>Execute command <code>PC_dsp_test_dl_algo.out</code> from <code>ti_dl/test</code> directory.</p>
<div class="fragment"><div class="line">user@ubuntu-pc$ cd ${TIDL_INSTALL_PATH}/ti_dl/test</div><div class="line">user@ubuntu-pc$ ./PC_dsp_test_dl_algo.out</div><div class="line"></div><div class="line">Processing config file #0 : testvecs/config/infer/public/caffe/tidl_infer_pelee.txt</div><div class="line"> ----------------------- TIDL Process with REF_ONLY FLOW ------------------------</div><div class="line"></div><div class="line">#    0 . .. T    8213.45  ... .... .....</div><div class="line">user@ubuntu-pc$ </div></div><!-- fragment --><p><b>Decoding the output</b></p>
<p>The test uses the <code>ti_dl/test/testvecs/input/ti_lindau_000020.bmp</code> as input image for object detection.</p>
<p>The test prints the time taken by PC simulation and stores the list of detected objects and the coordinates for each detected object in <code>ti_dl/test/testvecs/output/pelee.bin_ti_lindau_000020.bmp_000000.txt</code>. It also generates a post-processed output image at <code>ti_dl/test/testvecs/output/pelee.bin_ti_lindau_000020.bmp_000000_tidl_post_proc2.png</code> that shows the detected objects and the bounding boxes.</p>
<table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadNone">Input  </th><th class="markdownTableHeadNone">output --------------------&mdash;   </th></tr>
<tr class="markdownTableBody" class="markdownTableRowOdd">
<td class="markdownTableBodyNone"><div class="image">
<img src="in_ti_lindau_000020.bmp" alt="in_ti_lindau_000020.bmp"/>
<div class="caption">
Input image to object detection application</div></div>
  </td><td class="markdownTableBodyNone"><div class="image">
<img src="out_ti_lindau_000020.png" alt="out_ti_lindau_000020.png"/>
<div class="caption">
output of object detection application</div></div>
   </td></tr>
</table>
<h2><a class="anchor" id="tidl_gs_exec_jsegnet"></a>
Executing JSegNet21V2 model for semantic segmentation</h2>
<p>Add the following lines at the beginning of <code>ti_dl/test/testvecs/config/config_list.txt</code>:</p>
<div class="fragment"><div class="line">1 testvecs/config/infer/public/caffe/tidl_infer_jSegNet.txt</div><div class="line">0</div></div><!-- fragment --><p>Execute command <code>PC_dsp_test_dl_algo.out</code> from <code>ti_dl/test</code> directory.</p>
<div class="fragment"><div class="line">user@ubuntu-pc$ cd ${TIDL_INSTALL_PATH}/ti_dl/test</div><div class="line">user@ubuntu-pc$ ./PC_dsp_test_dl_algo.out</div><div class="line"></div><div class="line">Processing config file #0 : testvecs/config/infer/public/caffe/tidl_infer_jSegNet.txt </div><div class="line"> ----------------------- TIDL Process with REF_ONLY FLOW ------------------------</div><div class="line"></div><div class="line">#    0 . .. T    5236.66  ... .... .....</div><div class="line">user@ubuntu-pc$ </div></div><!-- fragment --><p>The test uses the <code>ti_dl/test/testvecs/input/ti_lindau_I00000.bmp</code> as input image for semantic segmentation.</p>
<p>The test prints the time taken by PC simulation and stores the generates a post-processed output image at <code>ti_dl/test/testvecs/output/jsegNet1024x512.bin_ti_lindau_I00000.bmp_000000_tidl_post_proc3.png</code> that shows the generated segmentation masks for the detected objects.</p>
<table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadNone">Input  </th><th class="markdownTableHeadNone">output --------------------&mdash;   </th></tr>
<tr class="markdownTableBody" class="markdownTableRowOdd">
<td class="markdownTableBodyNone"><div class="image">
<img src="in_ti_lindau_I00000.bmp" alt="in_ti_lindau_I00000.bmp"/>
<div class="caption">
Input image to semantic segmentation application</div></div>
  </td><td class="markdownTableBodyNone"><div class="image">
<img src="out_ti_lindau_I00000.png" alt="out_ti_lindau_I00000.png"/>
<div class="caption">
output of semantic segmentation application</div></div>
   </td></tr>
</table>
<blockquote class="doxtable">
<p><b>Note</b><br />
You can also execute all 3 of the above tests with a single command of <code>PC_dsp_test_dl_algo.out</code> by adding the following lines in the beginning of <code>ti_dl/test/testvecs/config/config_list.txt</code>: </p><pre class="fragment">1 testvecs/config/infer/public/tensorflow/tidl_infer_mobileNetv2.txt
1 testvecs/config/infer/public/caffe/tidl_infer_pelee.txt
1 testvecs/config/infer/public/caffe/tidl_infer_jSegNet.txt
0
</pre> </blockquote>
<h1><a class="anchor" id="tidl_gs_executeEVM"></a>
Executing imported models on Development Board</h1>
<p>The <code>.bin</code> files generated by <code>tidlModelImport</code> can be tested on development board. This section describes the steps required to execute the imported models on Jacinto7 SoC based development boards using the <code>TI_DEVICE_a72_test_dl_algo_host_rt.out</code> binary (distributed with the installation). We will use the same three models imported in previous section of <a href="#tidl_gs_import_models">Importing models</a>.</p>
<p><b>H/W requirements</b></p>
<ul>
<li>TI Jacinto7 EVM<ul>
<li>The EVM should be programmed to <b>SD-boot</b> mode as described in <a href="../../../../psdk_rtos/docs/user_guide/evm_setup_j721e.html#sd-boot-mode">SDK user guide</a></li>
</ul>
</li>
</ul>
<p><b>Preparing the SD card</b></p>
<ul>
<li>Run the below commands in you linux machine to copy the imported models, input files and binary files required to the TIDL application on target</li>
</ul>
<blockquote class="doxtable">
<pre class="fragment">user@ubuntu-pc$ cd ${PSDKRA_PATH}/vision_apps
user@ubuntu-pc$ make linux_fs_install_sd
</pre> </blockquote>
<p><b>Booting up the EVM</b></p>
<p>Insert the SD card in to the EVM and power on the EVM and wait for Linux to complete the boot. Log in as root and un below to execute the TIDL application</p>
<blockquote class="doxtable">
<p></p>
<p>root@ j7-evm:~# cd /opt/tidl_test root@ j7-evm:/opt/tidl_test# export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/lib root@ j7-evm:/opt/tidl_test# ./TI_DEVICE_a72_test_dl_algo_host_rt.out </p>
</blockquote>
<p><b>Decoding the output</b></p>
<div class="fragment"><div class="line">Processing config file #0 : testvecs/config/infer/public/caffe/tidl_infer_jSegNet.txt </div><div class="line">Syncd</div><div class="line"> ----------------------- TIDL Process with TARGET DATA FLOW ------------------------</div><div class="line"></div><div class="line">#    0 . .. TSC Mega Cycles =     8.58  ... .... .....</div><div class="line">Processing config file #0 : testvecs/config/infer/public/caffe/tidl_infer_pelee.txt </div><div class="line"> ----------------------- TIDL Process with TARGET DATA FLOW ------------------------</div><div class="line"></div><div class="line">#    0 . .. TSC Mega Cycles =   14.04  ... .... .....</div><div class="line">Processing config file #0 : testvecs/config/infer/public/tensorflow/tidl_infer_mobileNetv2.txt </div><div class="line"> ----------------------- TIDL Process with TARGET DATA FLOW ------------------------</div><div class="line"></div><div class="line">#    0 . .. TSC Mega Cycles =     6.33  ... A :   896, 1.0000, 1.0000,   896 .... .....</div></div><!-- fragment --><p>The test output is printed on console which shows the number of megacycles taken for each test case. Assuming C7x is running at 1 GHz, the time-taken-per-frame and FPS for each test can be calculated as:</p>
<blockquote class="doxtable">
<p><b>Time-taken-per-frame in milliseconds</b> = (1000 / C7x CPU clock in MHz) x <b>Number of mega cycles</b><br />
<b>FPS</b> = 1 / <b>Time-taken-per-frame in milliseconds</b> </p>
</blockquote>
<p>For example, From the output above:</p>
<table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadNone">Test  </th><th class="markdownTableHeadNone">Mega cycles count  </th><th class="markdownTableHeadNone" colspan="2">Time taken pe   </th></tr>
<tr class="markdownTableBody" class="markdownTableRowOdd">
<td class="markdownTableBodyNone">JSegNet21V2  </td><td class="markdownTableBodyNone">8.58  </td><td class="markdownTableBodyNone">8.58  </td><td class="markdownTableBodyNone">116.55   </td></tr>
<tr class="markdownTableBody" class="markdownTableRowEven">
<td class="markdownTableBodyNone">PeleeNet  </td><td class="markdownTableBodyNone">10.04  </td><td class="markdownTableBodyNone">10.04  </td><td class="markdownTableBodyNone">96.15   </td></tr>
<tr class="markdownTableBody" class="markdownTableRowOdd">
<td class="markdownTableBodyNone">MobileNetV2  </td><td class="markdownTableBodyNone">6.33  </td><td class="markdownTableBodyNone">6.33  </td><td class="markdownTableBodyNone">157.98   </td></tr>
</table>
<p>For <em>image classification</em> tests, the input class and the inferred class is also printed (e.g. in <em>MobileNetV2</em> test).</p>
<p>After all the tests are complete, the post processed images for <em>object detection</em> and <em>semantic segmentation</em> are stored in <code>testvecs/output</code>.</p>
<p><b>Validating test output</b></p>
<p>Take the SD card out of the EVM and plug it into PC. After the SD card is mounted in <code>${SDCARD_MOUNT_DIR}</code>, you can check the contents in <code>${SDCARD_MOUNT_DIR}/opt/tidl_test/testvecs/output</code>.</p>
<p>The post processed output files should be present in</p>
<ul>
<li><em>Object detection</em> output in <code>${SDCARD_MOUNT_DIR}/opt/tidl_test/testvecs/output/pelee.bin_ti_lindau_000020.bmp_000000_tidl_post_proc2.bmp</code></li>
<li><em>Semantic segmentation</em> output in <code>${SDCARD_MOUNT_DIR}/opt/tidl_test/testvecs/output/jsegNet1024x512.bin_ti_lindau_I00000.bmp_000000_tidl_post_proc3.bmp</code></li>
</ul>
<h1><a class="anchor" id="tidl_gs_summary"></a>
Summary</h1>
<p>This document provides a step-by-step approach towards getting started with <b>TIDL-RT</b>.</p>
<ol type="1">
<li>You can refer to the <b>TIDL-RT</b> section <a href="usergroup1.html">here</a><ol type="a">
<li>The list of all supported layers and their configurations can be found <a class="el" href="md_tidl_layers_info.html">here</a></li>
<li>The list of all CNN models validated by TI can be found <a class="el" href="md_tidl_models_info.html">here</a><ul>
<li>If you choose your back bone network as one of the network that TI has already validated, then we can expect a rapid deployment of the model</li>
</ul>
</li>
</ol>
</li>
<li>Import your trained network to <b>TIDL-RT</b> <code>.bin</code> files using <code>tidlModelImport</code> tool on PC.<ul>
<li>You can develop / train your deep learning application / network on PC using open frameworks (Tensorflow, Caffe or Pytorch)</li>
<li>Further details of <code>tidlModelImport</code> can be found <a class="el" href="md_tidl_model_import.html">here</a></li>
</ul>
</li>
<li>Validate the inference result from import process on host emulation, and make sure this produces expected output. Enable the post-processing (if applicable) to validate the output quickly.<ul>
<li>The details of post-processing can be found <a class="el" href="md_tidl_fsg_output_post_processing.html">here</a></li>
<li>Further details of <b>TIDL-RT</b> sample application can be found <a class="el" href="md_tidl_sample_test.html">here</a></li>
</ul>
</li>
<li>If you want to validate your model in SDK, please refer to <a href="../../../../vision_apps/docs/user_guide/DEMOS.html">SDK's demo / docs</a>.<ul>
<li>SDK also supports host emulation and we recommend this host emulation mode for debugging integration issues if any.</li>
</ul>
</li>
<li>Execute your network on Jacinto7 EVM to measure the performance using <b>TIDL-RT</b> target test application</li>
<li>You can refer to the troubleshooting guide <a class="el" href="md_tidl_fsg_steps_to_debug_mismatch.html">here</a> for debugging issues. </li>
</ol>
</div></div><!-- contents -->
</div><!-- doc-content -->
<!-- HTML footer for doxygen 1.8.11-->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer">Generated by
    <a href="http://www.doxygen.org/index.html">
    <img class="footer" src="doxygen.png" alt="doxygen"/></a> 1.8.14 </li>
  </ul>
</div>
</body>
</html>
