<!-- HTML header for doxygen 1.8.11-->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.14"/>
<title>TI Deep Learning Product User Guide: TIDL-RT Inference with Sample Application</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
  $(document).ready(initResizable);
/* @license-end */</script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectlogo"><img alt="Logo" src="ti_logo.png"/></td>
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">TI Deep Learning Product User Guide
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.14 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(document).ready(function(){initNavTree('md_tidl_sample_test.html','');});
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="headertitle">
<div class="title">TIDL-RT Inference with Sample Application </div>  </div>
</div><!--header-->
<div class="contents">
<div class="toc"><h3>Table of Contents</h3>
<ul><li class="level1"><a href="#tidl_inference_0">Introduction</a></li>
<li class="level1"><a href="#tidl_inference_1">Steps to run host emulation mode on PC</a></li>
<li class="level1"><a href="#tidl_inference_2">Inference Configuration Parameters</a></li>
<li class="level1"><a href="#tidl_inference_4">Steps to run Sample Application on EVM</a></li>
</ul>
</div>
<div class="textblock"><h1><a class="anchor" id="tidl_inference_0"></a>
Introduction</h1>
<p>This section provides steps to run imported model using TIDL-RT inference library and sample test application. Please refer <a class="el" href="md_tidl_model_import.html">TIDL Model Import</a> section for details on importing pre-trained models. User shall try this step only after validating the output of import step against expected results.</p>
<p>The Sample Application binaries available in "ti_dl/test/" can be use to run inference on imported models.</p>
<p>We have sample allocation built for Host PC (Emulation) and Target (J7ES EVM). The Host PC (Emulation) and Target shall produce same results.</p>
<p>User shall first run the The host emulation on PC (Windows or Linux) by following the steps mentioned here. Output can be validated against the expected results. After validating with host emulation mode, the inference for model can be done on EVM and output can be compared against output obtained from host emulation.</p>
<h1><a class="anchor" id="tidl_inference_1"></a>
Steps to run host emulation mode on PC</h1>
<div class="fragment"><div class="line">Usage:</div><div class="line">cd ti_dl/test</div><div class="line">&lt; Sample TIDL Binary &gt;</div><div class="line">Example:</div><div class="line">PC_dsp_test_dl_algo.out</div></div><!-- fragment --><p> This binary by default would read the configuration list file "ti_dl/test/testvecs/config/config_list.txt" and run all the configuration files available in the list file.</p>
<blockquote class="doxtable">
<p><b>Note</b><br />
It is possible to run a different configuration list by running it as:<br />
<br />
PC_dsp_test_dl_algo.out relative/path/to/some/other/config/list/txt<br />
<br />
It is also possible to run a single inference configuration file by running it as:<br />
<br />
PC_dsp_test_dl_algo.out s:relative/path/to/single/infer/config/txt<br />
</p>
</blockquote>
<h1><a class="anchor" id="tidl_inference_2"></a>
Inference Configuration Parameters</h1>
<table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadNone">Parameter  </th><th class="markdownTableHeadNone">Description   </th></tr>
<tr class="markdownTableBody" class="markdownTableRowOdd">
<td class="markdownTableBodyNone">netBinFile  </td><td class="markdownTableBodyNone">Input TIDL model with Net and Parameters - generated by Import tools   </td></tr>
<tr class="markdownTableBody" class="markdownTableRowEven">
<td class="markdownTableBodyNone">ioConfigFile  </td><td class="markdownTableBodyNone">Input and output buffer descriptor file for TIDL ivision interface - generated by Import tools   </td></tr>
<tr class="markdownTableBody" class="markdownTableRowOdd">
<td class="markdownTableBodyNone">inData  </td><td class="markdownTableBodyNone">File name for reading the Input tensors. inData is further interpreted based on inFileFormat as follows:<br />
 inFileFormat = 0 : inData is directly used for providing compressed image (JPEG/PNG/BMP). This is only supported for single input networks. <br />
 inFileFormat = 1 : inData is read as a raw binary file. Multiple inputs should be concatenated into a single binary file. Multiple frames should also be concatenated in a single binary file.<br />
 inFileFormat = 2 : inData is read as a text file which contains list of inputs, with each row corresponding to all the inputs to the network separated by space.<br />
 Note: Only BMP image format is supported for execution on EVM (target).   </td></tr>
<tr class="markdownTableBody" class="markdownTableRowEven">
<td class="markdownTableBodyNone">outData  </td><td class="markdownTableBodyNone">Output tensors File for Writing   </td></tr>
<tr class="markdownTableBody" class="markdownTableRowOdd">
<td class="markdownTableBodyNone">inFileFormat  </td><td class="markdownTableBodyNone">0: inData is read as Compressed Image (JPEG/PNG/BMP) <br />
 1: inData is read as a raw binary file. <br />
 2: inData is read from a text file containing the list of compressed images<br />
 When inFileformat = 1 then type of raw data can be defined using rawDataInElementType. If rawDataInElementType is not set then raw data type is assumed to be same as inElementType   </td></tr>
<tr class="markdownTableBody" class="markdownTableRowEven">
<td class="markdownTableBodyNone">rawDataInElementType  </td><td class="markdownTableBodyNone">This parameter is only applicable when inFileFormat is 1 and indicates the raw file's format. TIDL-RT test bench performs a conversion from rawDataInElementType to inElementType when these 2 are not same.<br />
 Supported values are:<br />
 0 : unsigned char<br />
 1 : signed char<br />
 2 : unsigned short<br />
 3 : signed short<br />
 6 : float<br />
   </td></tr>
<tr class="markdownTableBody" class="markdownTableRowOdd">
<td class="markdownTableBodyNone">numFrames  </td><td class="markdownTableBodyNone">Number of input tensors to be processed from the input file   </td></tr>
<tr class="markdownTableBody" class="markdownTableRowEven">
<td class="markdownTableBodyNone">postProcType  </td><td class="markdownTableBodyNone">Post processing on output tensor. 0 : Disable, 1- Classification top 1 and 5 accuracy, 2 â€“ Draw bounding box for OD, 3 - Pixel level color blending   </td></tr>
<tr class="markdownTableBody" class="markdownTableRowOdd">
<td class="markdownTableBodyNone">postProcDataId  </td><td class="markdownTableBodyNone">Output Tensor ID on which the Post processing needs to be performed, 0 : Default   </td></tr>
<tr class="markdownTableBody" class="markdownTableRowEven">
<td class="markdownTableBodyNone">quantRangeExpansionFactor  </td><td class="markdownTableBodyNone">Margin that needs to be applied on Feature map Range . Example 1.2 would apply add 20% margin to range values   </td></tr>
<tr class="markdownTableBody" class="markdownTableRowOdd">
<td class="markdownTableBodyNone">quantRangeUpdateFactor  </td><td class="markdownTableBodyNone">Rate at which the range values shall be updated after each process. Example 0.1 would apply add 10% to current process range and 90% running range. This parameter is only applicable for stats collection during import and is not used during inference.   </td></tr>
<tr class="markdownTableBody" class="markdownTableRowEven">
<td class="markdownTableBodyNone">debugTraceLevel  </td><td class="markdownTableBodyNone">Control for enabling trace of inference to be used for debugging purpose, supports 3 levels: 0,1 and 2 with increasing amount of tracing. Default 0   </td></tr>
<tr class="markdownTableBody" class="markdownTableRowOdd">
<td class="markdownTableBodyNone">writeTraceLevel  </td><td class="markdownTableBodyNone">Layer level tensor trace level. Default : 0, 0 - No Tensor Trace, 1- Fixed Point , 2- Padded Fixed Point, 3 - Floating point   </td></tr>
<tr class="markdownTableBody" class="markdownTableRowEven">
<td class="markdownTableBodyNone">writeOutput  </td><td class="markdownTableBodyNone">Write output tensors to file. Default : 1, 1 - All output tensors written to file in integer format, 2 - All output tensors written to file in float format, 0 - Each output tensor is compared against the file pointing to outData   </td></tr>
<tr class="markdownTableBody" class="markdownTableRowOdd">
<td class="markdownTableBodyNone">numItrPerf  </td><td class="markdownTableBodyNone">Number of iterations to be averaged for reporting Performance - Default : 1   </td></tr>
</table>
<blockquote class="doxtable">
<p><b>Note</b> <br />
It is possible to override a parameter in all the inference configuration files present in "ti_dl/test/testvecs/config/config_list.txt" by<br />
providing the parameter as an argument to the application. For example, to run all inferences with "writeTraceLevel" = 1,<br />
the application can be run as<br />
<br />
PC_dsp_test_dl_algo.out &ndash;writeTraceLevel 3<br />
<br />
This feature is available when using a configuration file other then the default "ti_dl/test/testvecs/config/config_list.txt":<br />
<br />
PC_dsp_test_dl_algo.out relative/path/to/some/other/config/list/txt &ndash;writeTraceLevel 3<br />
</p>
</blockquote>
<blockquote class="doxtable">
<p><b>Note</b><br />
The global override can then be further tuned for a particular inference by editing its entry in the configuration list file.<br />
For example to run jacintoNet11v2 with "writeTraceLevel" = 1 (after the global override of "writeTraceLevel" = 3), the entry can be:<br />
<br />
1 testvecs/config/infer/public/caffe/tidl_infer_jacintonet11v2.txt &ndash;writrTraceLevel 1<br />
</p>
</blockquote>
<blockquote class="doxtable">
<p><b>Note</b><br />
It is possible to override multiple parameters (both global overrides and test case specific overrides), for example:<br />
<br />
PC_dsp_test_dl_algo.out &ndash;writeTraceLevel 3 &ndash;debugTraceLevel 3<br />
<br />
</p>
</blockquote>
<p>Configuration files used for validation of models are provided in the "ti_dl/test/testvecs/config/infer/" folder for reference</p>
<p>Below is one example configuration file for Inference</p>
<div class="fragment"><div class="line">inFileFormat    = 2</div><div class="line">postProcType = 1</div><div class="line">numFrames   = 1</div><div class="line">netBinFile      = &quot;../testvecs/config/tidl_models/tidl_net_jacintonet11v2_np2quant.bin&quot;</div><div class="line">ioConfigFile    = &quot;../testvecs/config/tidl_models/tidl_io_jacintonet11v2_np2quant_1.txt&quot;</div><div class="line">inData  =   &quot;../testvecs/config/classification_list.txt&quot;</div><div class="line">outData =   &quot;../testvecs/output/airshow_j11.bin&quot;</div></div><!-- fragment --><p>On Successful execution the output tensor will be generated in as binary raw file in the path specified by "outData".</p>
<h1><a class="anchor" id="tidl_inference_4"></a>
Steps to run Sample Application on EVM</h1>
<p>The above inference test can be executed on Jacinto7 SoC using the <code>TI_DEVICE_a72_test_dl_algo_host_rt.out</code> binary (distributed with the installation). This section will describe the steps required to run the imported models on target.</p>
<p><b>H/W requirements</b></p>
<ul>
<li>TI Jacinto7 EVM<ul>
<li>The EVM should be programmed to <b>SD-boot</b> mode as described in <a href="../../../../psdk_rtos/docs/user_guide/evm_setup_j721e.html#sd-boot-mode">SDK user guide</a></li>
</ul>
</li>
</ul>
<p><b>Preparing the SD card</b></p>
<ul>
<li>Run the below commands in you linux machine to copy the imported models, input files and binary files required to the TIDL application on target</li>
</ul>
<blockquote class="doxtable">
<pre class="fragment">user\@ubuntu-pc\$ cd ${PSDKRA_PATH}/vision_apps
user\@ubuntu-pc\$ make linux_fs_install_sd
</pre> </blockquote>
<p><b>Booting up the EVM</b></p>
<p>Insert the SD card in to the EVM and power on the EVM and wait for Linux to complete the boot. Log in as root and run below to execute the TIDL application </p><blockquote class="doxtable">
<pre class="fragment">root@ j7-evm:~# cd /opt/vision_apps
root@ j7-evm:~# source ./vision_apps_init.sh
</pre> </blockquote>
<blockquote class="doxtable">
<pre class="fragment">root@ j7-evm:~# cd /opt/tidl_test
root@ j7-evm:/opt/tidl_test# export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/lib
root@ j7-evm:/opt/tidl_test# ./TI_DEVICE_a72_test_dl_algo_host_rt.out
</pre> </blockquote>
<p><b>Decoding the output</b></p>
<div class="fragment"><div class="line">Processing config file #0 : testvecs/config/infer/public/caffe/tidl_infer_jSegNet.txt </div><div class="line">Syncd</div><div class="line"> ----------------------- TIDL Process with TARGET DATA FLOW ------------------------</div><div class="line"></div><div class="line">#    0 . .. TSC Mega Cycles =     8.58  ... .... .....</div><div class="line">Processing config file #0 : testvecs/config/infer/public/caffe/tidl_infer_pelee.txt </div><div class="line"> ----------------------- TIDL Process with TARGET DATA FLOW ------------------------</div><div class="line"></div><div class="line">#    0 . .. TSC Mega Cycles =   9.77  ... .... .....</div><div class="line">Processing config file #0 : testvecs/config/infer/public/tensorflow/tidl_infer_mobileNetv2.txt </div><div class="line"> ----------------------- TIDL Process with TARGET DATA FLOW ------------------------</div><div class="line"></div><div class="line">#    0 . .. TSC Mega Cycles =     6.33  ... A :   896, 1.0000, 1.0000,   896 .... .....</div></div><!-- fragment --><p>The test output is printed on console which shows the number of megacycles taken for each test case. Assuming C7x is running at 1 GHz, the time-taken-per-frame and FPS for each test can be calculated as:</p>
<blockquote class="doxtable">
<p><b>Time-taken-per-frame in milliseconds</b> = (1000 / C7x CPU clock in MHz) x <b>Number of mega cycles</b><br />
<b>FPS</b> = 1 / <b>Time-taken-per-frame in milliseconds</b> </p>
</blockquote>
<p>For example, From the output above :</p>
<table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadNone">Test  </th><th class="markdownTableHeadNone">Mega cycles count  </th><th class="markdownTableHeadNone">Time taken per frame (ms)  </th><th class="markdownTableHeadNone">FPS   </th></tr>
<tr class="markdownTableBody" class="markdownTableRowOdd">
<td class="markdownTableBodyNone">JSegNet21V2  </td><td class="markdownTableBodyNone">8.58  </td><td class="markdownTableBodyNone">8.58  </td><td class="markdownTableBodyNone">116.55   </td></tr>
<tr class="markdownTableBody" class="markdownTableRowEven">
<td class="markdownTableBodyNone">PeleeNet  </td><td class="markdownTableBodyNone">9.77  </td><td class="markdownTableBodyNone">9.77  </td><td class="markdownTableBodyNone">102.30   </td></tr>
<tr class="markdownTableBody" class="markdownTableRowOdd">
<td class="markdownTableBodyNone">MobileNetV2  </td><td class="markdownTableBodyNone">6.33  </td><td class="markdownTableBodyNone">6.33  </td><td class="markdownTableBodyNone">157.98   </td></tr>
</table>
<p><b>Note : Above numbers are representative numbers, to get the real numbers for these networks, you should run the same on EVM</b></p>
<p>For <em>image classification</em> tests, the input class and the inferred class is also printed (e.g. in <em>MobileNetV2</em> test).</p>
<p>After all the tests are complete, the post processed images for <em>object detection</em> and <em>semantic segmentation</em> are stored in <code>testvecs/output</code>.</p>
<p><b>Validating test output</b></p>
<p>Take the SD card out of the EVM and plug it into PC. After the SD card is mounted in <code>${SDCARD_MOUNT_DIR}</code>, you can check the contents in <code>${SDCARD_MOUNT_DIR}/opt/tidl_test/testvecs/output</code>.</p>
<p>The post processed output files should be present in</p>
<ul>
<li><em>Object detection</em> output in <code>${SDCARD_MOUNT_DIR}/opt/tidl_test/testvecs/output/pelee.bin_ti_lindau_000020.bmp_000000_tidl_post_proc2.bmp</code></li>
<li><em>Semantic segmentation</em> output in <code>${SDCARD_MOUNT_DIR}/opt/tidl_test/testvecs/output/jsegNet1024x512.bin_ti_lindau_I00000.bmp_000000_tidl_post_proc3.bmp</code> </li>
</ul>
</div></div><!-- contents -->
</div><!-- doc-content -->
<!-- HTML footer for doxygen 1.8.11-->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer">Generated by
    <a href="http://www.doxygen.org/index.html">
    <img class="footer" src="doxygen.png" alt="doxygen"/></a> 1.8.14 </li>
  </ul>
</div>
</body>
</html>
